import os, hashlib, json
from fastapi import APIRouter, UploadFile, File, Depends, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
from sqlalchemy.orm import Session
from sqlalchemy import insert

from app.db import SessionLocal
from app.db import schema
from app.db.models import FileRecord
from app.db.schema import FileOut
from app.core.static_analysis import sniff_mime, extract_excerpt, analyze_bytes, analyze_file, get_cached_report, test_zip_detection
from app.cache.redis_client import get_redis
from app.cache.keys import file_data_key
from app.config import get_settings
from app.services.ai_model_service import get_ai_model_service
from app.services.ensemble_model_service import get_ensemble_model_service
from app.services.gemini_service import get_gemini_service
from app.external.virustotal import get_virustotal_client


router = APIRouter(prefix="/scan", tags=["scan"])
UPLOAD_DIR = "uploaded_files"
os.makedirs(UPLOAD_DIR, exist_ok=True)

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

@router.post("/upload", response_model=schema.FileOut)
async def upload(file: UploadFile, background_tasks: BackgroundTasks, db: Session = Depends(get_db), settings=Depends(get_settings)):
    file_bytes = await file.read()
    filename = file.filename or "upload.bin"

    mime = sniff_mime(file_bytes=file_bytes)
    size = len(file_bytes)
    excerpt = extract_excerpt(mime=mime, max_len=settings.EXCERPT_LIMIT, file_bytes=file_bytes)

    sha256 = hashlib.sha256(file_bytes).hexdigest()

    result = db.execute(
        insert(FileRecord).values(
            filename=filename,
            mime_type=mime,
            size_bytes=size,
            content_excerpt=excerpt,
            source="upload",
            source_url=None,
            page_url=None,
            sha256=sha256,
        ).returning(
            FileRecord.id, FileRecord.filename, FileRecord.mime_type, FileRecord.size_bytes, FileRecord.content_excerpt
        )
    )
    rec = result.first()
    db.commit()

    try:
        print(f"[DEBUG] analyze_bytes í˜¸ì¶œ ì‹œì‘ - íŒŒì¼: {filename}")
        report = analyze_bytes(
            file_bytes=file_bytes, 
            filename=filename, 
            ttl_sec=settings.SHARE_TTL_SECONDS, 
            use_cache=True,
            include_virustotal=True,
            original_filename=filename
        )
        print(f"[DEBUG] analyze_bytes í˜¸ì¶œ ì™„ë£Œ - report íƒ€ì…: {type(report)}")
        
        if isinstance(report, dict):
            print(f"[DEBUG] analyze_bytes ê²°ê³¼ - is_archive: {report.get('file', {}).get('is_archive')}")
            print(f"[DEBUG] analyze_bytes ê²°ê³¼ - embedded_files ìˆ˜: {len(report.get('embedded_files', []))}")
        else:
            print(f"[DEBUG] analyze_bytes ê²°ê³¼ê°€ dictê°€ ì•„ë‹˜: {report}")

        print(f"[DEBUG] AI ëª¨ë¸ ì„œë¹„ìŠ¤ ì‹œì‘")
        ensemble_model_service = get_ensemble_model_service()
        print(f"[DEBUG] ensemble_model_service.model_loaded: {ensemble_model_service.model_loaded}")
        
        if ensemble_model_service.model_loaded and report:
            if 'embedded_files' not in report:
                print(f"[DEBUG] ì¼ë°˜ íŒŒì¼ AI ì˜ˆì¸¡ ì‹œì‘")
                try:
                    ai_prediction = ensemble_model_service.predict_malware_type(report)
                    if ai_prediction:
                        report['ai_prediction'] = ai_prediction
                        # DEBUG: feature_importance í™•ì¸
                        fi = ai_prediction.get("ai_analysis", {}).get("model_info", {}).get("enhanced_features", {}).get("feature_importance")
                        print(f"ğŸ“Š ì¼ë°˜ íŒŒì¼ feature_importance ì¡´ì¬: {fi is not None}, ê°œìˆ˜: {len(fi) if fi else 0}")
                        
                        # Gemini ì„¤ëª… ìƒì„±
                        try:
                            hard_labels = ai_prediction.get("ai_analysis", {}).get("predicted_types", [])
                            is_only_normal = len(hard_labels) == 1 and hard_labels[0] == 'Normal'
                            print(f"ğŸ” ì¼ë°˜ íŒŒì¼ Gemini ì²´í¬: is_only_normal={is_only_normal}, hard_labels={hard_labels}")
                            
                            # Normal íŒŒì¼ë„ Gemini ì„¤ëª… ìƒì„± (SHAPì€ ì´ë¯¸ ì„œë¹„ìŠ¤ì—ì„œ ìŠ¤í‚µë¨)
                            gemini_service = get_gemini_service()
                            print(f"ğŸ” Gemini ì„œë¹„ìŠ¤ ìƒíƒœ: initialized={gemini_service.initialized if gemini_service else 'None'}")
                            if gemini_service and gemini_service.initialized:
                                virustotal_result = None
                                try:
                                    vt_client = get_virustotal_client()
                                    vt_response = vt_client.get_file_analysis(sha256)
                                    if vt_response and vt_response.get("available"):
                                        virustotal_result = vt_response
                                except Exception as e:
                                    print(f"VT failed: {e}")
                                
                                feature_importance = ai_prediction.get("ai_analysis", {}).get("model_info", {}).get("enhanced_features", {}).get("feature_importance")
                                
                                # Normal íŒŒì¼ì€ feature_importanceê°€ ì—†ì–´ë„ Gemini í˜¸ì¶œ
                                print(f"âœ… Gemini í˜¸ì¶œ ì‹œì‘ (Normal={is_only_normal})")
                                gemini_explanation = gemini_service.explain(ai_prediction, virustotal_result, feature_importance)
                                if gemini_explanation:
                                    print(f"âœ… Gemini ì„¤ëª… ìƒì„± ì™„ë£Œ: {type(gemini_explanation)}")
                                    report["gemini_explanation"] = gemini_explanation
                                else:
                                    print(f"âš ï¸ Gemini ì„¤ëª…ì´ ë¹„ì–´ìˆìŒ")
                        except Exception as e:
                            print(f"âŒ Gemini failed: {e}")
                            import traceback
                            traceback.print_exc()
                        
                    print(f"[DEBUG] ì¼ë°˜ íŒŒì¼ AI ì˜ˆì¸¡ ì™„ë£Œ")
                except Exception as e:
                    print(f"[ERROR] ì¼ë°˜ íŒŒì¼ AI ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                    pass
            else:
                print(f"[DEBUG] ì••ì¶• íŒŒì¼ ë‚´ë¶€ íŒŒì¼ë“¤ AI ì˜ˆì¸¡ ì‹œì‘")
                for i, item in enumerate(report.get('embedded_files', []) or []):
                    rep = item.get('report')
                    if rep:
                        try:
                            print(f"[DEBUG] ë‚´ë¶€ íŒŒì¼ {i+1} AI ì˜ˆì¸¡ ì¤‘: {item.get('filename')}")
                            ai_prediction = ensemble_model_service.predict_malware_type(rep)
                            if ai_prediction:
                                rep['ai_prediction'] = ai_prediction
                                # DEBUG: feature_importance í™•ì¸
                                fi = ai_prediction.get("ai_analysis", {}).get("model_info", {}).get("enhanced_features", {}).get("feature_importance")
                                print(f"ğŸ“Š ë‚´ë¶€ íŒŒì¼ {item.get('filename')} feature_importance ì¡´ì¬: {fi is not None}, ê°œìˆ˜: {len(fi) if fi else 0}")
                                
                                # Gemini ì„¤ëª… ìƒì„±
                                try:
                                    hard_labels = ai_prediction.get("ai_analysis", {}).get("predicted_types", [])
                                    is_only_normal = len(hard_labels) == 1 and hard_labels[0] == 'Normal'
                                    print(f"ğŸ” ë‚´ë¶€ íŒŒì¼ Gemini ì²´í¬: is_only_normal={is_only_normal}, hard_labels={hard_labels}")
                                    
                                    # Normal íŒŒì¼ë„ Gemini ì„¤ëª… ìƒì„± (SHAPì€ ì´ë¯¸ ì„œë¹„ìŠ¤ì—ì„œ ìŠ¤í‚µë¨)
                                    gemini_service = get_gemini_service()
                                    if gemini_service and gemini_service.initialized:
                                        # ë‚´ë¶€ íŒŒì¼ì˜ hash ê°€ì ¸ì˜¤ê¸°
                                        file_hash = rep.get('file', {}).get('hash', {}).get('sha256', sha256)
                                        
                                        virustotal_result = None
                                        try:
                                            vt_client = get_virustotal_client()
                                            vt_response = vt_client.get_file_analysis(file_hash)
                                            if vt_response and vt_response.get("available"):
                                                virustotal_result = vt_response
                                        except Exception as e:
                                            print(f"VT failed for embedded file: {e}")
                                        
                                        feature_importance = ai_prediction.get("ai_analysis", {}).get("model_info", {}).get("enhanced_features", {}).get("feature_importance")
                                        
                                        # Normal íŒŒì¼ì€ feature_importanceê°€ ì—†ì–´ë„ Gemini í˜¸ì¶œ
                                        print(f"âœ… ë‚´ë¶€ íŒŒì¼ Gemini í˜¸ì¶œ ì‹œì‘ (Normal={is_only_normal})")
                                        gemini_explanation = gemini_service.explain(ai_prediction, virustotal_result, feature_importance)
                                        if gemini_explanation:
                                            print(f"âœ… ë‚´ë¶€ íŒŒì¼ Gemini ì„¤ëª… ìƒì„± ì™„ë£Œ")
                                            rep["gemini_explanation"] = gemini_explanation
                                        else:
                                            print(f"âš ï¸ ë‚´ë¶€ íŒŒì¼ Gemini ì„¤ëª…ì´ ë¹„ì–´ìˆìŒ")
                                except Exception as e:
                                    print(f"âŒ Gemini failed for embedded file: {e}")
                                    import traceback
                                    traceback.print_exc()
                                
                            print(f"[DEBUG] ë‚´ë¶€ íŒŒì¼ {i+1} AI ì˜ˆì¸¡ ì™„ë£Œ")
                        except Exception as e:
                            print(f"[ERROR] ë‚´ë¶€ íŒŒì¼ {i+1} AI ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                            rep['ai_prediction'] = None
                print(f"[DEBUG] ì••ì¶• íŒŒì¼ ë‚´ë¶€ íŒŒì¼ë“¤ AI ì˜ˆì¸¡ ì™„ë£Œ")

        cache_data = {
            "filename": filename,
            "mime_type": mime,
            "size_bytes": size,
            "sha256": sha256,
            "file_id": rec.id,
            "report": report
        }
        
        if report and isinstance(report, dict):
            is_archive = report.get('file', {}).get('is_archive', False)
            embedded_files = report.get('embedded_files', [])
            print(f"[DEBUG] scan.py - is_archive: {is_archive}, embedded_files ìˆ˜: {len(embedded_files)}")
            if embedded_files:
                print(f"[DEBUG] ì²« ë²ˆì§¸ embedded file: {embedded_files[0].get('filename')}")

        redis_client = get_redis()
        file_cache_key = file_data_key(sha256)
        print(f"[DEBUG] Redis ìºì‹œ ì €ì¥ - í‚¤: {file_cache_key}")
        print(f"[DEBUG] ì €ì¥ë  ë°ì´í„°: filename={cache_data.get('filename')}, report_type={type(cache_data.get('report'))}")
        if isinstance(cache_data.get('report'), dict):
            report_data = cache_data.get('report')
            print(f"[DEBUG] report ë‚´ìš©: is_archive={report_data.get('file', {}).get('is_archive')}, embedded_filesìˆ˜={len(report_data.get('embedded_files', []))}")
        redis_client.setex(file_cache_key, settings.SHARE_TTL_SECONDS, json.dumps(cache_data, ensure_ascii=False))

    except Exception as e:
        print(f"[ERROR] analyze_bytes ì‹¤íŒ¨: {e}")
        import traceback
        print(f"[ERROR] ìƒì„¸ ì—ëŸ¬ ì •ë³´: {traceback.format_exc()}")
        background_tasks.add_task(analyze_bytes, file_bytes, filename)

    resp = {
        "ok": True,
        "id": rec.id,
        "filename": rec.filename,
        "mime_type": rec.mime_type,
        "size_bytes": rec.size_bytes,
        "excerpt_preview": (rec.content_excerpt or "")[:300],
        "sha256": sha256
    }
    
    print(f"[DEBUG] scan.py ì—…ë¡œë“œ ì‘ë‹µ: {resp}")
    try:
        vt = (report or {}).get('virustotal') if isinstance(report, dict) else None
        ss = (vt or {}).get('scan_summary') or {}
    except Exception:
        pass
    return JSONResponse(resp)

@router.get("/recent", response_model=list[FileOut])
def recent(db: Session = Depends(get_db)):
    rows = db.query(FileRecord)\
             .order_by(FileRecord.id.desc())\
             .limit(50).all()
    return [
        {
            "id": r.id, "filename": r.filename, "mime_type": r.mime_type,
            "size_bytes": r.size_bytes,
            "excerpt_preview": (r.content_excerpt or "")[:300]
        } for r in rows
    ]

@router.post("/analyze/{file_id}")
def analyze_by_id(file_id: int, db: Session = Depends(get_db)):
    rec = db.query(FileRecord).filter(FileRecord.id == file_id).first()
    if not rec:
        raise HTTPException(status_code=404, detail="file not found")

    report = analyze_file(rec.path, ttl_sec=3600, use_cache=True)
    return {"file_id": rec.id, "sha256": report["file"]["hash"]["sha256"], "report": report}


@router.get("/report/{sha256}")
def get_report(sha256: str):
    report = get_cached_report(sha256)
    if report:
        return report
    
    r = get_redis()
    cached_data = r.get(file_data_key(sha256))
    if cached_data:
        try:
            data = json.loads(cached_data)
            report = data.get("report")
            
            while isinstance(report, dict) and "report" in report and isinstance(report["report"], dict):
                report = report["report"]
            
            return report
        except Exception:
            pass
    
    raise HTTPException(status_code=404, detail="report not found")

@router.get("/model/status")
def get_model_status():
    ensemble_service = get_ensemble_model_service()
    ai_service = get_ai_model_service()
    
    return {
        "ensemble_model": ensemble_service.get_model_status(),
        "legacy_ai_model": {
            "model_loaded": ai_service.model_loaded,
            "models_dir_exists": ensemble_service.models_dir.exists()
        }
    }

@router.post("/model/reload")
def reload_models():
    ensemble_service = get_ensemble_model_service()
    ensemble_success = ensemble_service.reload_model()
    
    ai_service = get_ai_model_service()
    ai_success = ai_service.load_models()
    
    return {
        "ensemble_model": {
            "success": ensemble_success,
            "message": "Ensemble model reloaded successfully" if ensemble_success else "Failed to reload ensemble model"
        },
        "legacy_ai_model": {
            "success": ai_success,
            "message": "Legacy AI model reloaded successfully" if ai_success else "Failed to reload legacy AI model"
        }
    }

@router.post("/test-zip-detection")
async def test_zip_detection_endpoint(file: UploadFile = File(...)):
    try:
        file_bytes = await file.read()
        result = test_zip_detection(file_bytes, file.filename)
        return JSONResponse({
            "ok": True,
            "test_result": result
        })
    except Exception as e:
        return JSONResponse({
            "ok": False,
            "error": str(e)
        }, status_code=500)